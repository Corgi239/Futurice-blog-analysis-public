{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('../../data/final/futurice_blog_data.csv', sep='\\t', index_col='index')\n",
    "\n",
    "full_df = full_df.dropna(how='any', axis=0) #Get rid of any blogs that could cause models to crash\n",
    "\n",
    "#Formatting values into easy-to-use arrays for models\n",
    "texts = full_df['text'].values\n",
    "titles = full_df['title'].values\n",
    "categories = full_df['category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer, WordNetLemmatizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guting's preprocessing functions\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def lemmatize_stem(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text, min_len=3):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stem(token))\n",
    "    return result\n",
    "\n",
    "#Preprocessing texts\n",
    "lem_texts = []\n",
    "for t in texts:\n",
    "    l = preprocess(t)\n",
    "    lem_texts.append(' '.join(l))\n",
    "\n",
    "print(lem_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Features with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mainly going to use this model as features\n",
    "tf_idf_vectorizer = TfidfVectorizer(use_idf=True, norm='l2')\n",
    "\n",
    "tf_idf_matrix = tf_idf_vectorizer.fit_transform(lem_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color table to keep colors consistent throughout graphs\n",
    "color_table = {\n",
    "    \"Opinion\": '#000000',              #Black\n",
    "    \"Technology\": '#0009FF',           #Blue\n",
    "    \"Innovation & Design\": '#27E4DD', #Cyan\n",
    "    \"Ways of Working\": '#CCCC00', #Yellow\n",
    "    \"Culture\": '#FF007F',       #Dark Pink\n",
    "    \"Events\": '#FD69F3',        #Pink\n",
    "    \"Emerging Tech\": '#FF7700', #Orange\n",
    "    \"Strategy\": '#FF0000', #Red\n",
    "    \"News\": '#401E00',     #Brown\n",
    "    \"Learning\": '#063E40', #Dark Blue\n",
    "    \"Projects\": '#193300', #Ugly Green\n",
    "    \"Product\": '#808080' #Grey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_matrix = tf_idf_matrix.todense()\n",
    "color_real = [color_table[x] for x in categories]\n",
    "\n",
    "embeddings = TSNE(n_components = 2)\n",
    "Y = embeddings.fit_transform(dense_matrix)\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Culture seems to be relatively well clustered. If classifier show some logic there then there is definitely some potential in clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chekcing whether vectors are classifiable with KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a map from text to integer for easier plotting\n",
    "tag_to_num = {\"Opinion\": 0,\n",
    "              \"Technology\": 1,\n",
    "              \"Innovation & Design\": 2,\n",
    "              \"Ways of Working\": 3,\n",
    "              \"Culture\": 4,\n",
    "              \"Events\": 5,\n",
    "              \"Emerging Tech\": 6,\n",
    "              \"Strategy\": 7,\n",
    "              \"News\": 8,\n",
    "              \"Learning\": 9,\n",
    "              \"Projects\": 10,\n",
    "              \"Product\": 11}\n",
    "\n",
    "tags = [tag_to_num[elem] for elem in categories]\n",
    "\n",
    "\n",
    "k_neigh = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "\n",
    "#500 training elements(Just randomly chose this for)\n",
    "k_neigh.fit(tf_idf_matrix[:500], tags[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix on whole remaining text\n",
    "plot_confusion_matrix(k_neigh, tf_idf_matrix, tags, labels=np.unique(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lab = k_neigh.predict(tf_idf_matrix)\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=pred_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0\n",
    "for i in range(len(pred_lab)):\n",
    "    if pred_lab[i] != tags[i]:\n",
    "        err += 1\n",
    "print(err/len(pred_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further testing in this same manner showed that Culture showed an error rate of only 4 percent. This probably means that the texts can indeed be classified but the current tags are not properly representing groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing 3 clustering models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=9) #9 comes from Guting's topic modeling\n",
    "\n",
    "kmeans_model.fit(tf_idf_matrix)\n",
    "kmeans_l = kmeans_model.labels_\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=kmeans_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(silhouette_score(tf_idf_matrix, kmeans_model.labels_))  #Score close to 0, so not good neither bad. We can at least see some clusters occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "best_result = -2\n",
    "best_params = (0, 1)\n",
    "\n",
    "for n in range(1, 110, 1):\n",
    "    for m in range(2, 10):\n",
    "        temp_mod = DBSCAN(eps=n/10, min_samples=m, metric='cosine').fit(tf_idf_matrix)\n",
    "        if len(np.unique(temp_mod.labels_)) == 1:\n",
    "            sil = -2\n",
    "        else:\n",
    "            sil = silhouette_score(tf_idf_matrix, temp_mod.labels_)\n",
    "        if sil > best_result:\n",
    "            best_result = sil\n",
    "            best_params = (n, m)\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_db = DBSCAN(eps=0.9, min_samples=7, metric='cosine').fit(tf_idf_matrix)\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=best_db.labels_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's avoid DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglo cluster\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agglo_model = AgglomerativeClustering(n_clusters=9, affinity='euclidean').fit(dense_matrix)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=agglo_model.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Agglo and KMeans seem usable, let's see whether they can cluster Culture properly like the classifier does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_comp = pd.DataFrame({'title': np.array(titles), 'real': np.array(categories), 'pred': np.array(kmeans_l)}, columns=['title', 'real', 'pred'])\n",
    "\n",
    "for i in range(0, 9):\n",
    "    print(str(i) + \": \" + str(kmeans_comp[kmeans_comp['pred'] == i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 9):\n",
    "    temp = {}\n",
    "    for elem in kmeans_comp[kmeans_comp['pred'] == i]['real'].values:\n",
    "        if elem in temp:\n",
    "            temp[elem] += 1\n",
    "        else:\n",
    "            temp[elem] = 1\n",
    "    temp = {k: v for k, v in sorted(temp.items(), key=lambda item: item[1])}\n",
    "    print(str(i) + \": \" + str(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_comp = pd.DataFrame({'title': np.array(titles), 'real': np.array(categories), 'pred': np.array(agglo_model.labels_)}, columns=['title', 'real', 'pred'])\n",
    "\n",
    "for i in range(0, 9):\n",
    "    print(str(i) + \": \" + str(agglo_comp[agglo_comp['pred'] == i].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 9):\n",
    "    temp = {}\n",
    "    for elem in agglo_comp[agglo_comp['pred'] == i]['real'].values:\n",
    "        if elem in temp:\n",
    "            temp[elem] += 1\n",
    "        else:\n",
    "            temp[elem] = 1\n",
    "    temp = {k: v for k, v in sorted(temp.items(), key=lambda item: item[1])}\n",
    "    print(str(i) + \": \" + str(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welp, both of them do well in both clustering Culture, but also clustering technology. I'm gonna run manual tests you can ignore and just skip to the TLDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR:\n",
    "KMeans does a great job clustering, and while it is not regular in its clusters, some seem to appear everytime. Those are:\n",
    "-FutuStories and similar style docs\n",
    "-Mobility\n",
    "-Energy\n",
    "-Data\n",
    "-Cloud\n",
    "-Strategy\n",
    "\n",
    "Some others that appear but sometimes get merged with others:\n",
    "-Health\n",
    "-Robotics\n",
    "-Design\n",
    "\n",
    "In our case, I saved a model's results which seemed to do a good job clustering without overfitting some topics. These results are saved  in cluster_temp_save.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I did my original clustering with blog_text, so gonna make sure both contain the same docs\n",
    "\n",
    "analytics = pd.read_csv(\"../../data/final/futurice_blog_data.csv\", sep='\\t')\n",
    "\n",
    "save = pd.read_csv(\"../../data/interim/cluster_temp_save.csv\", sep='²')\n",
    "s_title = save['title'].values\n",
    "s_pred = save['cluster_pred'].values\n",
    "for i in range(len(s_pred)):\n",
    "    if s_pred[i] == \"Company oriented Strategy\":\n",
    "        s_pred[i] = \"Company\"\n",
    "\n",
    "to_remove = []\n",
    "pg_views = []\n",
    "for i in range(len(s_title)):\n",
    "    idk = analytics[analytics['title'] == s_title[i]]['pageviews'].values\n",
    "    if len(idk) == 0:\n",
    "        to_remove.append(i)\n",
    "        continue\n",
    "    if len(idk) > 1:\n",
    "        pg_views.append(idk.sum())\n",
    "    else:\n",
    "        pg_views.append(idk[0])\n",
    "\n",
    "for elem in to_remove:\n",
    "    s_title = np.delete(s_title, elem)\n",
    "    s_pred = np.delete(s_pred, elem)\n",
    "\n",
    "print(len(s_title), len(s_pred), len(pg_views))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pageviews per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "views = {}\n",
    "\n",
    "for i in range(len(s_title)):\n",
    "    if s_pred[i] in count.keys():\n",
    "        count[s_pred[i]] += 1\n",
    "        views[s_pred[i]] += pg_views[i]\n",
    "    else:\n",
    "        count[s_pred[i]] = 1\n",
    "        views[s_pred[i]] = pg_views[i]\n",
    "\n",
    "avg = {}\n",
    "for k in count.keys():\n",
    "    avg[k] = views[k]/count[k]\n",
    "\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.bar(avg.keys(), avg.values())\n",
    "plt.title('Average pageviews per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating above by combining similar topics\n",
    "avg_2 = {\n",
    "    'Futustories': avg['Futustories'],\n",
    "    'Design/Strategy': (views['Company'] + views['Mobility'] + views['Strategy'] + views['Design'] + views['Strategy'])/(count['Company'] + count['Mobility'] + count['Strategy'] + count['Design'] + count['Strategy']),\n",
    "    'Tech': (views['Data'] + views['AI'] + views['Cloud'])/(count['Data'] + count['AI'] + count['Cloud']),\n",
    "    'Futurice': avg['Futurice']\n",
    "}\n",
    "\n",
    "print(avg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.bar(avg_2.keys(), avg_2.values())\n",
    "plt.title('Average views per category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_num = {\n",
    "    'Futustories': '#000000',\n",
    "    'Company': '#0009FF',\n",
    "    'Data': '#27E4DD',\n",
    "    'Mobility': '#CCCC00',\n",
    "    'Strategy': '#FF007F',\n",
    "    'AI': '#FD69F3',\n",
    "    'Futurice': '#FF7700',\n",
    "    'Design': '#401E00',\n",
    "    'Energy': '#FF0000',\n",
    "    'Cloud': '#063E40'\n",
    "}\n",
    "\n",
    "big_to_color = {\n",
    "    'Tech': '#000000',\n",
    "    'Design/Strategy': '#FF0000',\n",
    "    'Futustories': '#27E4DD',\n",
    "    'Futurice': '#FF7700',\n",
    "}\n",
    "\n",
    "big_tag = []\n",
    "for tag in s_pred:\n",
    "    if tag in ['Data', 'AI', 'Cloud']:\n",
    "        big_tag.append('Tech')\n",
    "    elif tag in ['Company', 'Mobility', 'Strategy', 'Design', 'Energy']:\n",
    "        big_tag.append(\"Design/Strategy\")\n",
    "    else:\n",
    "        big_tag.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.DataFrame({'tf': tf_idf_matrix, 'category': np.array(s_pred), 'big_category': np.array(big_tag), 'x': Y[:, 0],  'y': Y[:, 1]}, columns=['tf', 'category', 'big_category', 'x', 'y'])\n",
    "fig, ax = plt.subplots()\n",
    "for tag in cluster_to_num.keys():\n",
    "    tmp = mapping[mapping['category'] == tag]\n",
    "    \n",
    "    ax.scatter(tmp['x'].values, tmp['y'].values, c=cluster_to_num[tag], label=tag)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for tag in big_to_color.keys():\n",
    "    tmp = mapping[mapping['big_category'] == tag]\n",
    "    \n",
    "    ax.scatter(tmp['x'].values, tmp['y'].values, c=big_to_color[tag], label=tag)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
